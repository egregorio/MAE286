{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from helper import l2_norm, poisson_2d_jacobi, poisson_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "ny, nx = 101, 101\n",
    "xmin, xmax = 0.0, 1.0\n",
    "ymin, ymax = -0.5, 0.5\n",
    "Lx = xmax - xmin\n",
    "Ly = ymax - ymin\n",
    "dx = Lx / (nx - 1)\n",
    "dy = Ly / (ny - 1)\n",
    "\n",
    "x = numpy.linspace(xmin, xmax, num=nx)\n",
    "y = numpy.linspace(ymin, ymax, num=ny)\n",
    "X, Y = numpy.meshgrid(x,y)\n",
    "\n",
    "b = (-2.0 * (numpy.pi / Lx) * (numpy.pi / Ly) *\n",
    "     numpy.sin(numpy.pi * X / Lx) *\n",
    "     numpy.cos(numpy.pi * Y / Ly))\n",
    "\n",
    "p0 = numpy.zeros((ny, nx))\n",
    "\n",
    "p_exact = poisson_solution(x, y, Lx, Ly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_2d_steepest_descent(p0, b, dx, dy, maxiter=20000, rtol=1e-6):\n",
    "    \n",
    "    def A(p):\n",
    "        # apply laplacian operator to p\n",
    "        return (-4.0 * p[1:-1, 1:-1] +\n",
    "                p[1:-1, :-2] + p[1:-1, 2:] +\n",
    "                p[:-2, 1:-1] + p[2:, 1:-1]) / dx**2\n",
    "    p = p0.copy()\n",
    "    r = numpy.zeros_like(p)\n",
    "    Ar = numpy.zeros_like(p)\n",
    "    conv = []\n",
    "    diff = rtol + 1\n",
    "    ite = 0\n",
    "    while diff > rtol and ite < maxiter:\n",
    "        pk = p.copy()\n",
    "        r[1:-1, 1:-1] = b[1:-1, 1:-1] - A(p) # residual\n",
    "        Ar[1:-1, 1:-1] = A(r)   # laplacian of residual\n",
    "        alpha = numpy.sum(r * r) / numpy.sum(r * Ar) # step size\n",
    "        p = pk + alpha * r # update solution\n",
    "        #boundary conditions!...are automatically enforced\n",
    "        #compute relative L2-norm of difference\n",
    "        diff = l2_norm(p, pk)\n",
    "        conv.append(diff)\n",
    "        ite += 1\n",
    "    return p, ite, conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ites = 2  conv_sd = 1.3307695446303778e-16\n"
     ]
    }
   ],
   "source": [
    "p, ites, conv_sd = poisson_2d_steepest_descent(p0, b, dx, dy, maxiter=20000, rtol=1e-10)\n",
    "print('ites =', ites, ' conv_sd =', conv_sd[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_2d_conjugate_gradient(p0, b, dx, dy, maxiter=20000, rtol=1e-6):\n",
    "    def A(p):\n",
    "        # used to apply laplacian to stuff!\n",
    "        return (-4.0 * p[1:-1, 1:-1] +\n",
    "                p[1:-1, :-2] + p[1:-1, 2:] +\n",
    "                p[:-2, 1:-1] + p[2:, 1:-1]) / dx**2\n",
    "    p = p0.copy()\n",
    "    r = numpy.zeros_like(p) # initial residual\n",
    "    Ad = numpy.zeros_like(p)\n",
    "    conv = []\n",
    "    diff = rtol +1\n",
    "    ite = 0\n",
    "    r[1:-1, 1:-1] = b[1:-1, 1:-1] - A(p) #compute initial residual\n",
    "    d = r.copy() # initial search direction to be the residual\n",
    "    while diff > rtol and ite < maxiter:\n",
    "        pk = p.copy()\n",
    "        rk = r.copy()\n",
    "        Ad[1:-1, 1:-1] = A(d) # laplacian of search direction\n",
    "        alpha = numpy.sum(r * r) / numpy.sum(d * Ad) # step size\n",
    "        p = pk + alpha * d # update solution!!\n",
    "        r = rk - alpha * Ad # update residual\n",
    "        #update search direction\n",
    "        beta = numpy.sum(r * r) / numpy.sum(rk * rk)\n",
    "        d = r + beta * d\n",
    "        #boundary conditions automatically enforced\n",
    "        # compute relative L2-norm of difference\n",
    "        diff = l2_norm(p, pk)\n",
    "        conv.append(diff)\n",
    "        ite += 1\n",
    "    return p, ite, conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ites = 2  conv_sd = 1.3307695446303778e-16\n"
     ]
    }
   ],
   "source": [
    "p, ites, conv_cg = poisson_2d_conjugate_gradient(p0, b, dx, dy,\n",
    "                                                 maxiter=20000,\n",
    "                                                 rtol=1e-10)\n",
    "print('ites =', ites, ' conv_sd =', conv_sd[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.225076220929585e-05"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute relative L2-norm of the error\n",
    "l2_norm(p, p_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacobi relaxation: 31227 iterations to reach a relative difference of 9.997923503623598e-11\n"
     ]
    }
   ],
   "source": [
    "p, ites, conv_jacobi = poisson_2d_jacobi(p0, b, dx, dy,\n",
    "                                         maxiter=40000,\n",
    "                                         rtol=1e-10)\n",
    "print('Jacobi relaxation: {} iterations '.format(ites) +\n",
    "      'to reach a relative difference of {}'.format(conv_jacobi[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify the source term to make some more difficult solutions!!!!!\n",
    "b = (numpy.sin(numpy.pi * X / Lx) *\n",
    "     numpy.cos(numpy.pi * Y / Ly) +\n",
    "     numpy.sin(6.0 * numpy.pi * X / Lx) * \n",
    "     numpy.sin(6.0 * numpy.pi * Y / Ly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31226\n",
      "27059\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "maxiter, rtol = 40000, 1e-10\n",
    "p, ites, conv = poisson_2d_jacobi(p0, b, dx, dy,\n",
    "                                  maxiter=maxiter, rtol=rtol)\n",
    "print(ites)\n",
    "p, ites, conv = poisson_2d_steepest_descent(p0, b, dx, dy,\n",
    "                                            maxiter=maxiter,\n",
    "                                            rtol=rtol)\n",
    "print(ites)\n",
    "p, ites, conv = poisson_2d_conjugate_gradient(p0, b, dx, dy,\n",
    "                                              maxiter=maxiter,\n",
    "                                              rtol=rtol)\n",
    "print(ites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the CG method is the best one...thats the point I think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
